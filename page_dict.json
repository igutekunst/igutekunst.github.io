{
    "/nav": {
        "title": "nav",
        "date": "2024-09-22",
        "tags": [],
        "publish": true,
        "url": "/nav",
        "path": "nav.md",
        "content": "# Example Site\n\n## Navigation\n- [Blog](blog)\n- [About](about)\n- [Contact](contact)"
    },
    "/contact": {
        "title": "Contact Me",
        "date": "2024-09-22",
        "tags": [],
        "publish": true,
        "url": "/contact",
        "path": "contact.md",
        "content": "# Connect With Me\n\nYou can connect with me in a few ways:\n\n - Connect on [Matrix](https://matrix.org) [@isaac:iamthatiam.org](https://matrix.to/#/@isaac:iamthatiam.org)\n - Comment on this or any page"
    },
    "/./2024-09-17-deploying-django-to-digital-ocean": {
        "title": "Deploying Django to Digital Ocean",
        "date": "2024-09-17",
        "tags": [
            "devops",
            "django"
        ],
        "publish": true,
        "url": "/./2024-09-17-deploying-django-to-digital-ocean",
        "path": "django-deploy-notes.md",
        "content": "Although not strictly part of the [[blog/01-personal-infrastructure]] series, this blog post will discuss building and deploying a basic Django application.\n\n\nSecrets:\n\n- Postgres\n- Django admin\n- Django token\n- SSH Keys\n- Ansible Vault Password\n\nAnsible\n\n2 Docker Images\n\n- Nginx\n- Django\n\nQuestions:\n\nShould .env file be backed into container? No\n - Can be loaded by  `compose.yaml`\n - Possibly store in ansible vault, then copied to production box\n\nWhat server deploys to production\nProbably a DroneCI runner. It will need an SSH deploy key to prod DO box.\n\nDigital Ocean Load Balancer\nDO Box, with docker compose situation. This has nginx, postgres, celery etc.\n\nShould I pay DO for a managed database? Probably\n\nWhat does local development look like?\n\nThere will be a a few environments: \n- Fully local with sqlite\n- Local in compose (possibly should add a DNS situation and run through `gateway`)\n-"
    },
    "/": {
        "title": "Programming Reality",
        "date": "2024-08-31",
        "tags": [],
        "publish": true,
        "url": "/",
        "path": "index.md",
        "content": "Welcome to Programming Reality, a site about changing the nature of reality, one line of code at a time.\n\n\n\n## Featured Posts {: .featured-posts}\n - [[blog/03-simple-automation]]{: .featured-post}\n - [[blog/01-personal-infrastructure]]{: .featured-post}\n - [[blog/00-welcome]]{: .featured-post}"
    },
    "/about": {
        "title": "About",
        "date": "2024-09-22",
        "tags": [],
        "publish": true,
        "url": "/about",
        "path": "about.md",
        "content": "# About the Site\nThis is a personal website for Isaac Harrison Gutekunst. I've created this site to share my exploration of programming reality. The main focus of this is highly technical articles about computer programming, engineering, and [[philosophy]]. \n\n## Content\n\nThe site is structured primarily as a \"blog\", where I write about projects I am working on, or small pieces of knowledge I've acquired over time. \n\n## Technical Aspects of the Site\n\nThis site is hosted on Github Pages, and generated using a custom static site generator written in Python. It uses a customized [Bootstrap](https://getbootstrap.com) for CSS. It generates the entire site from a collection of markdown files, with the YAML [`frontmatter`](https://dpericich.medium.com/what-is-front-matter-and-how-is-it-used-to-create-dynamic-webpages-9d8dc053b457) and custom syntax being inflated into metadata and content on the site.\n\nI am aware the colors, typography, and layout can be improved. I decided it was more important to get the site out than to get it perfect. If you'd like to help with CSS, don't hesitate to [[contact|contact]] me."
    },
    "/blog/2024-08-27-welcome-to-programming-reality": {
        "title": "Welcome to Programming Reality",
        "date": "2024-08-27",
        "tags": [
            "blog",
            "philosophy",
            "devops"
        ],
        "publish": true,
        "url": "/blog/2024-08-27-welcome-to-programming-reality",
        "path": "blog/00-welcome.md",
        "content": "[Read on Substack](https://programmingreality.substack.com/p/welcome-to-programming-reality)\n\n[Read on LinkedIn](https://www.linkedin.com/pulse/welcome-programming-reality-isaac-gutekunst-a02ic/)\n\nWelcome to my website and blog. Join me as I share my exploration of reality through the lens of language, and primarily machine-readable language.\n\nI will group my writing into three or more primary categories:\n\n1) My journey working on long-term projects. Posts in this category will be highly technical, and involve topics like computer programming, distributed systems, databases, networking, protocols and more.\n\n2) General musings on the \"Nature of Reality\". I'll typically tag these as \"philosophy\".\n\n3) Miscellaneous things I'm learning. I'll tag these as \"did-you-know\".\n\nI will kick off this journey by introducing my first long-term project: Building a \"Personal Cloud\", using Infrastructure as Code (IaC) tools and my best attempt at building something production-ready.\n\n## Programming Reality\n\nProgramming Reality as phrase is intended to evoke the idea that reality is flexible, and can be programmed with intention. People have always programmed reality with their words by telling stories. The stories we tell each other shape how we see the world, and perhaps even shape the structure of reality itself. In the current age, the programming is becoming more explicit and less occulted. People write computer programs that capture intentions, and then when placed into the right environment have real measurable affects on the physical world. I can tap my fingers on a piece of glass in a certain pattern and  30 minutes later, someone will bring food to my door. This is the magic of Uber Eats on an iPhone using the Internet.\n\n\n# About Me\nIn my professional career, I've spent over a decade working to build various computer systems, primarily for robotics, consumer electronics and aerospace. I've written code that is likely running in mars, running on a satellite orbiting overhead, running inside the headphones worn by millions of people, and running in many more glamorous and not so glamorous environments.\n\nPersonally, I've always been drawn to look closely at the inner workings of everything. I am drawn to understand how light bulbs function, and also why people go to war. I love looking at the structure of companies, families and societies big and small. I see patterns repeating at every level of abstraction, from the organization of ants, to the arrangement of code within a distributed system. \n\n## Why I'm Publishing this Site\n\nI love the world, and feel like sharing. I like building cool stuff! I think everything about life is amazing, and want to share that!\n\nI have so many ideas in my head that I love and want to see take physical form. I've decided to take the next step and start writing about them publicly."
    },
    "/blog/2024-09-22-deploying-services-like-plex-behind-an-nginx-reverse-proxy": {
        "title": "Deploying Services like Plex Behind an Nginx Reverse Proxy",
        "date": "2024-09-22",
        "tags": [
            "blog",
            "development",
            "infrastructure",
            "ansible"
        ],
        "publish": true,
        "url": "/blog/2024-09-22-deploying-services-like-plex-behind-an-nginx-reverse-proxy",
        "path": "blog/07-nginx-reverse-proxy.md",
        "content": "In this post, I describe a method for hosting any straightforward web service behind an [nginx](http://nginx.org) reverse proxy with automatically renewing Let's Encrypt SSL Certificates.\n\nThere are numerous web applications that can be self-hosted. I love checking out [awesome-selfhosted](https://github.com/awesome-selfhosted/awesome-selfhosted) on GitHub for ideas. These services differ in many ways: they are written in different languages, have different methods for hosting, handling SSL, and more. Hosting them easily with an automatically renewing SSL certificate is quite simple using `nginx` in a reverse proxy configuration.\n\n## Architecture\n\n\n![Architecture diagram with internet, proxy and 3 services](/images/drawio/nginx-reverse-proxy.svg)\n\nIn this setup, there is a computer running `nginx` with a public IP address. There is a DNS record for every service behind the proxy. I typically use one DNS A record for the `nginx` reverse proxy and create a `CNAME` record for each service.\n\nThis minimizes the amount of code and potentially vulnerable software running on a publicly accessible computer. Certbot can run in one place, easily updating all SSL certificates, and `nginx` can terminate SSL quickly and reliably.\n\nAll the backend services can therefore run unencrypted on port 80, as they are behind a firewall with private IPs in a trusted environment. This simplifies deploying services, as a bespoke SSL configuration is not required.\n\n**Security Improvements**\nAlthough running on port 80 in the private address space is \"fine,\" it would be more secure to use SSL between `nginx` and the services. However, doing this manually is quite annoying, and setting up a proper Certificate Authority and secrets management strategy is beyond the scope of this article. In a later article, I'll describe how to further secure this setup once I have [Ansible Vault](https://www.vaultproject.io) running in a private \"core services\" cluster.\n\n## Step By Step\n\nIf you want to recreate something similar, you may follow these steps:\n\n### 1. DNS Setup\n\nConfigure your DNS provider to have a CNAME or A record for each service that you wish to host, pointing to the `nginx` server. For example, `plex.example.com` should point to the IP address of \"Nginx with Certbot\" in the diagram above.\n\nThis is necessary so that A) you can connect to your service, and B) Certbot can issue a certificate.\n\nFor example:\n\n```\n\tgateway.example.com.     300\tIN\t    A\t123.123.123.123\n\tplex.example.com.        300\tCNAME\tgateway.example.com.\n\tblog.example.com.        300\tCNAME\tgateway.example.com.\n\tother.example.com.       300\tCNAME\tgateway.example.com.\n```\n\n\n## 2. nginx setup\n\n### Prerequisites \n\nThis section assumes that you have `nginx` installed on a server. If not, please install it. Digital Ocean has a comprehensive guide that I recommend: [Installing Nginx on Ubuntu 20.04](https://www.digitalocean.com/community/tutorials/how-to-install-nginx-on-ubuntu-20-04).\n\nThis guide covers more than is strictly necessary, but it's good information to know.\n\n### Configuration\n\nFor each service behind `nginx`, you will need a `server` block somewhere in the collection of files that `nginx` loads for its configuration.\n\nTypically, there is a core configuration file `/etc/nginx/nginx.conf`, as well as one or more **available** sites in `/etc/nginx/sites-available` that are enabled by creating a symlink from `/etc/nginx/sites-enabled`. When `nginx` starts up, it looks at `nginx.conf`, which in turn includes all the files in `sites-enabled` (`include /etc/nginx/modules-enabled/*.conf;`). \n\nFor a basic service, you can start with something like this:\n\n```\n# /etc/nginx/sites-available/foo\nupstream foo_server {\n        server 10.0.0.20:80;\n}\n\nserver {\n    server_name foo.example.com;\n\n    location / {\n        proxy_pass http://foo_server;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n\t}\n\tlisten 80;\n\n}\n\n```\n\n### Notes\nThere are a few things to keep in mind:\n\n1. The upstream `foo_server` must be unique. Multiple upstream directives with the same name is an error\n2. If you are hosting multiple services on one machine, you'll need to make them listen on different ports, rather than port 80.\n3. When you run `certbot --nginx` later, it will edit this file\n4. Some services require some additional configuration options\n\n### Testing and Enabling\n\nOnce you are happy with your base nginx configuration file, create a symlink from `sites-enabled`:\n\n```bash\n$ sudo ln -s /etc/nginx/sites-available/foo /etc/nginx/sites-enabled\n```\n\nTest your configuration by running:\n\n```\n$ nginx -t\nnginx: the configuration file /etc/nginx/nginx.conf syntax is ok\nnginx: configuration file /etc/nginx/nginx.conf test is successful\n```\n\nIf it does not show an output like this, edit the file and keep checking until it passes.\n\nThen reload nginx with\n\n```bash\nnginx -s reload\n2024/09/22 21:31:16 [notice] 1183285#1183285: signal process started\n```\n\nIf all is good, you should be able to access your server at `foo.example.com`.\n\n### Troubleshooting\n\n1. Verify that you can access the \"backend\" via it's internal private IP. \n\n2. check the `nginx` logs\n\n```bash\ntail -f /var/log/nginx/error.log\n```\n\n3. Verify you can ping the backend from the reverse proxy host\n4. Check the logs from the backend\n\n## 3. Get an SSL Certificate that automatically renews\n\n[Certbot](https://certbot.eff.org) in combination with [Let's Encrypt](https://letsencrypt.org) makes it very easy to get a free SSL certificate. Digital Ocean has another great article on this. Check out [How To Secure Nginx with Let's Encrypt on Ubuntu 20.04](https://www.digitalocean.com/community/tutorials/how-to-secure-nginx-with-let-s-encrypt-on-ubuntu-20-04)\n\nIf you just want to jump into it, it's as simple as :\n\n\n### Install Certbot\n\n```bash\nsudo apt install certbot python3-certbot-nginx\n```\n\n\n### Run Certbot\n\n```bash\ncertbot --nginx\n```\n\nFollow the prompts, and you are off to the races.\n\n\n## 4. Review Updated nginx configuration\n\nOpen up the `/etc/nginx/sites-available/foo` in your favorite text editor.\n\n```\nupstream foo_server {\n        server 10.0.0.20:11280;\n}\n\nserver {\n    server_name foo.example.com;\n\n    location /.well-known/acme-challenge/ {\n        root /var/www/certbot;\n    }\n\n    location / {\n        proxy_pass http://foo_server;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n\n\n    listen 443 ssl; # managed by Certbot\n    ssl_certificate /etc/letsencrypt/live/foo.example.com/fullchain.pem; # managed by Certbot\n    ssl_certificate_key /etc/letsencrypt/live/foo.example.com/privkey.pem; # managed by Certbot\n    include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot\n    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot\n\n}\n\n\nserver {\n    if ($host = foo.example.com) {\n        return 301 https://$host$request_uri;\n    } # managed by Certbot\n\n\n    server_name foo.example.com;\n    listen 80;\n    return 404; # managed by Certbot\n\n\n}\n```\n\nNotice that it made a few changes:\n\n1. Added a new `server` block that only listens on port 80 and redirects to `https` on port 443.\n2. Changed the first `server` block to listen on port 443 with SSL enabled.\n3. Added a key, certificate, and two other configuration files.\n\n### Notes for Running Plex Server\n\nTo run Plex efficiently behind an `nginx` reverse proxy, you can make some additional edits to the configuration file.\n\nCheck out [plex nginx.conf](https://github.com/toomuchio/plex-nginx-reverseproxy/blob/master/nginx.conf) on GitHub for an extensively tweaked file.\n\nI've settled on a subset of the tweaks, notably:\n\n- HTTP/2\n- Plex headers\n- WebSocket support\n\nI did not add gzip compression or OCSP stapling, but these seem like good ideas.\n\n```\nupstream plex {\n    server 10.0.0.22:32400;\n}\n\nserver {\n    server_name plex.example.com;\n\n    listen 443 ssl http2; # Added http2\n\n    # Plex-specific configuration\n    client_max_body_size 100M;\n    proxy_buffering off;\n\n    location / {\n        proxy_pass https://plex;\n        proxy_ssl_verify off;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n        proxy_set_header Sec-WebSocket-Extensions $http_sec_websocket_extensions;\n        proxy_set_header Sec-WebSocket-Key $http_sec_websocket_key;\n        proxy_set_header Sec-WebSocket-Version $http_sec_websocket_version;\n\n        # Plex-specific headers\n        proxy_set_header X-Plex-Client-Identifier $http_x_plex_client_identifier;\n        proxy_set_header X-Plex-Device $http_x_plex_device;\n        proxy_set_header X-Plex-Device-Name $http_x_plex_device_name;\n        proxy_set_header X-Plex-Platform $http_x_plex_platform;\n        proxy_set_header X-Plex-Platform-Version $http_x_plex_platform_version;\n        proxy_set_header X-Plex-Product $http_x_plex_product;\n        proxy_set_header X-Plex-Version $http_x_plex_version;\n\n        # WebSocket support\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n    }\n}\n```\n\n\n### Notes for Ansible or other Configuration Management Setup\n\nThere is nothing you need to do here unless you plan on automatically updating the configuration file using a tool like Ansible. If so, you will need to add some logic to your Ansible role to check for the presence of valid SSL certificates. If valid certificates are found, render the full \"post certbot\" file. If not, render the basic one, run certbot, and then render the \"post certbot\" file."
    },
    "/blog/2024-09-15-personal-infrastructure-part-3:-quality-of-life-improvements-with-justfile-automation": {
        "title": "Personal Infrastructure Part 3: Quality of Life Improvements with Justfile Automation",
        "date": "2024-09-15",
        "tags": [
            "blog",
            "development",
            "infrastructure",
            "ansible",
            "django"
        ],
        "publish": true,
        "url": "/blog/2024-09-15-personal-infrastructure-part-3:-quality-of-life-improvements-with-justfile-automation",
        "path": "blog/03-simple-automation.md",
        "content": "![Image of high tech secure vault](/images/ansible-vault-automation-1.webp)\n\n\nIn this post, I describe how I like to use Justfiles to make running common tasks easier.\n\n## 1. Justfile:\n\nI created a Justfile to streamline the setup and execution of various tasks in our project. \n\nJustfiles are simplified modern alternatives to Makefiles. Here's a quick overview of what our Justfile does:\n\nI prefer them for simple task execution that doesn't require the complexity and dependency resolution of Makefiles. I also like avoiding Makefile syntax whenever possible.\n\n\nThe `Justfile` has recipes for the following:\n\n- Creating and activating a virtual environment.\n- Installing or verifying dependencies (Ansible and Cookiecutter).\n- Generating a vault password for Ansible.\n- Creating secrets for our infrastructure.\n- Setting up the entire environment in one go.\n- Running the Ansible playbook.\n\nThe Justfile simplifies our workflow by encapsulating complex commands into simple, memorable recipes. For example, instead of remembering long command sequences, we can now just run `just setup` to prepare our environment or `just ansible_playbook` to execute our Ansible playbook.\n\nThis approach not only saves time but also reduces the likelihood of errors, ensuring consistency across different development environments and making it easier for team members to contribute to the project.\n\n\n```Justfile\n# Justfile\n\n# Set the shell to bash\nset shell := [\"bash\", \"-cu\"]\n\n# Define a variable for the virtual environment directory\nvenv_dir := \"venv\"\n\n# Recipe to create or activate the virtual environment\nvenv:\n    if [ ! -d {{venv_dir}} ]; then \\\n        python3 -m venv {{venv_dir}}; \\\n    fi\n    . {{venv_dir}}/bin/activate\n\n# Recipe to install or verify Ansible and Cookiecutter are installed\ninstall_dependencies:\n    just venv\n    . {{venv_dir}}/bin/activate\n    if ! pip show ansible > /dev/null 2>&1; then \\\n        pip install ansible; \\\n    else \\\n        echo \"Ansible is already installed\"; \\\n    fi\n    if ! pip show cookiecutter > /dev/null 2>&1; then \\\n        pip install cookiecutter; \\\n    else \\\n        echo \"Cookiecutter is already installed\"; \\\n    fi\n\ncreate_vault_password:\n    python3 physical-server-ansible-playbook/get_vault_pass.py generate\n\ncreate_secrets:\n    python3 physical-server-ansible-playbook/create_secrets.py cir\n\n# Recipe to set up the environment (create venv and install dependencies)\nsetup:\n    just venv\n    just install_dependencies\n    just create_vault_password\n\n# Add more tasks as needed\n\n\nansible_playbook:\n    just setup\n    cd physical-server-ansible-playbook && ansible-playbook playbook.yml\n\nping:\n    just setup\n    cd physical-server-ansible-playbook && ansible -i inventory/hosts all -m ping\n\n```\n\n### 1.1 Makefile\n\nTo really push the automation to the next level, I made a Makefile that install [just](https://github.com/casey/just).\n\n\n```bash\n# Install Just\n\n# Detect the operating system\nUNAME_S := $(shell uname -s)\n\n# Default installation method (for unsupported systems)\ninstall_just_default:\n\t@echo \"Unsupported operating system. Please install Just manually.\"\n\n# macOS installation\nifeq ($(UNAME_S),Darwin)\ninstall_just:\n\t@if command -v port >/dev/null 2>&1; then \\\n\t\tsudo port install just; \\\n\telif command -v brew >/dev/null 2>&1; then \\\n\t\tbrew install just; \\\n\telse \\\n\t\techo \"Neither MacPorts nor Homebrew is installed. Installing Homebrew...\"; \\\n\t\t/bin/bash -c \"$$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"; \\\n\t\tbrew install just; \\\n\tfi\nelse\n\n# Debian-based Linux installation\nifeq ($(UNAME_S),Linux)\ninstall_just:\n\t@if command -v apt-get >/dev/null 2>&1; then \\\n\t\tsudo apt-get update && sudo apt-get install -y curl; \\\n\t\tcurl --proto '=https' --tlsv1.2 -sSf https://just.systems/install.sh | sudo bash -s -- --to /usr/local/bin; \\\n\telse \\\n\t\techo \"This doesn't appear to be a Debian-based system. Please install Just manually.\"; \\\n\tfi\nelse\n\n# Fallback to default installation method\ninstall_just: install_just_default\n\nendif\nendif\n\n.PHONY: install_just install_just_default\n\n```\n\n\n## Next Steps: Creating initial secrets automatically\n\nAfter I can store values securely, I'd like to automate the creation of initial random secrets used for various services.\n\nRead more about it in my post: [[blog/04-initial-secrets]]"
    },
    "/blog/2024-09-14-personal-infrastructure-part-2:-setting-up-secret-storage-for-ansible": {
        "title": "Personal Infrastructure Part 2: Setting up Secret Storage for Ansible",
        "date": "2024-09-14",
        "tags": [
            "blog",
            "development",
            "infrastructure",
            "ansible"
        ],
        "publish": true,
        "url": "/blog/2024-09-14-personal-infrastructure-part-2:-setting-up-secret-storage-for-ansible",
        "path": "blog/02-ansible-secrets.md",
        "content": "![Image of high tech secure vault](/images/ansible-vault-1.webp)\n\n\nIn this post, I'm going to explain one way to store secrets when using Ansible.\n\nAnsible has the ability to encrypt and decrypt data, using what it calls the [Ansible Vault](https://docs.ansible.com/ansible/latest/vault_guide/index.html).\n\n## Introduction\n\nMany services require passwords, keys and other secrets. Some are used to access systems and services outside of the ansible deployment, and many are often randomly generated during the initial setup for use within the deployment.\n\nIn both cases, I like encrypting these using Ansible Vault. To make it a bit smoother, I take advantage of a few Ansible features.\nAfter digging around, and doing this a few times, I've settled on the following technique:\n\n1. I use a Python script to retrieve the key used by Ansible Vault to encrypt and decrypt. \n2. Edit `ansible.cfg` to use this script\n3. Make another python script and Ansible Playbook that create new random secrets for usage within playbooks.\n\n\n## Pieces\n\n### 1. Store Vault Password\n\nI made a simple python script that for storing a password in the system's protected storage. This should work on Windows, MacOS and Linux (in Desktop mode), though I haven't tested on anything except MacOS:\n\n```Python\n#!/usr/bin/env python\n\nimport os\nimport sys\nimport keyring\nimport getpass\nimport argparse\nimport secrets\nimport string\n\nAPP_ENV = os.getenv(\"APP_ENV\",\"development\")\n\nSERVICE_NAME = \"AnsibleVault\"\nACCOUNT_NAME = f\"ansible_vault_password_rev_{APP_ENV}\"\n\ndef get_vault_password():\n    password = keyring.get_password(SERVICE_NAME, ACCOUNT_NAME)\n    return password\n\ndef set_vault_password(generate=False):\n    if generate:\n        password = ''.join(secrets.choice(string.ascii_letters + string.digits + string.punctuation) for _ in range(32))\n        print(\"Generated a new secure password.\")\n    else:\n        password = getpass.getpass(\"Enter New Ansible Vault password: \")\n    keyring.set_password(SERVICE_NAME, ACCOUNT_NAME, password)\n    return password\n\ndef clear_vault_password():\n    keyring.delete_password(SERVICE_NAME, ACCOUNT_NAME)\n    print(\"Ansible Vault password has been cleared.\")\n\nif __name__ == \"__main__\":\n    if len(sys.argv) == 1:\n        password = get_vault_password()\n        if not password:\n            sys.stderr.write(\"No Ansible Vault password found. Please set or generate one.\")\n            sys.exit(1)\n        print(password)\n    else:\n        parser = argparse.ArgumentParser(description=\"Manage Ansible Vault password\")\n        parser.add_argument(\"action\", choices=[\"set\", \"generate\", \"clear\"], help=\"Action to perform\")\n        args = parser.parse_args()\n\n        if args.action == \"set\":\n            set_vault_password()\n            print(\"Ansible Vault password has been set.\")\n        elif args.action == \"generate\":\n            stored_password = keyring.get_password(SERVICE_NAME, ACCOUNT_NAME)\n            if stored_password:\n                print(\"Ansible Vault password already exists. Use set to set it, or clear to clear it.\")\n            else:\n                set_vault_password(generate=True)\n                print(\"Ansible Vault password has been set.\")\n        elif args.action == \"clear\":\n            clear_vault_password()\n```\n\n### Configure Ansible to use Python Script\n\nI edited `ansible.cfg` to use the new python script:\n\n```bash\ncat ansible.cfg                                                                                                                                                                                                                master \u2b06 \u2716 \u25fc\n[defaults]\ninventory = inventory/hosts\nremote_user = ansible_user\nprivate_key_file = ~/.ssh/id_ed25519_aslan_ansible\nhost_key_checking = False\n+++ vault_password_file = get_vault_pass.py\ninterpreter_python = auto_silent\n```\n\n**Important:**  Be sure to make sure `get_vault_pass.py` is executable and has an appropriate `#!/usr/bin/env python` or similar.\n\n\n### Create initial vault password\n\n```bash\n    APP_ENV=staging python3 physical-server-ansible-playbook/get_vault_pass.py generate\n    APP_ENV=development python3 physical-server-ansible-playbook/get_vault_pass.py generate\n    APP_ENV=production python3 physical-server-ansible-playbook/get_vault_pass.py generate\n    \n```"
    },
    "/blog/2024-09-13-personal-infrastructure-part-1:-introduction-and-basic-ansible-setup": {
        "title": "Personal Infrastructure Part 1: Introduction and Basic Ansible Setup",
        "date": "2024-09-13",
        "tags": [
            "blog",
            "development",
            "infrastructure"
        ],
        "publish": true,
        "url": "/blog/2024-09-13-personal-infrastructure-part-1:-introduction-and-basic-ansible-setup",
        "path": "blog/01-ansible-setup.md",
        "content": "![Image of computers and power line infrastructure](images/ansible-1.webp)\n\n\nIn this first step, I'm going to build Ansible skeleton project and test connectivity.  I will explain the motivation, my existing setup, how I setup Ansible, and how I make the process a bit smoother and more secure.\n\n# Introduction and Motivation\n\nEventually I will build out [[blog/01-personal-infrastructure]]. I will have a collection of files that given access to a handful of physical or virtual machines will \"build\" a complete foundation for a personal microservices project. To avoid moving too slowly, I will avoid trying to make any part of this process perfectly generic. It will work with my chosen hardware, software and 3rd party services. I will make some effort so that anyone following alone should be able to recreate something similar. \n\n## My Existing Setup\n\n### Hardware\n\n- [Protectli Vault](https://protectli.com/vault-6-port/), configured with 64GB RAM, and a Samsung 4TB SSD.\n- AMD Threadripper desktop with 128GB RAM, and 8TB of SSD storage.\n- Old MSI laptop with 16GB or RAM and 1 TB of SSD Storage\n- Digital Ocean Intel SSD VM with 4GB of RAM and 100 GB or storage.\n- Smaller Protectli Vault running pfSense\n\n### Existing Use Cases\n\n Right now I host a few personal web services:\n\n - [Plex](plex.tv)\n - My \"spiritual\" website: [i am that i am](https://iamthatiam.org), an \"almost\" static site that uses a bit of Django.\n - A personal [Sentry](sentry.io) instance.\n - A personal [Jenkins](jenkins.io) instance\n - A [Plausible Analytics](https://plausible.io) instance\n - A few more\n\n\n### Network Topology\n\nAll the physical hardware is connected via a gigabit switch behind pfSense router. The pfSense router is running a [Wireguard](https://www.wireguard.com) server that I connect to with my roaming Mac laptop, and iPhone. All these servers are on the `10.0.0.0/24` subnet. All Wireguard clients are on the `10.2.0.0/24` subnet, with a specific tunnel for each one.\n\nMy VM provided by Digital Ocean is running Debian 12. It has a permanent Wireguard tunnel back to the pfSense box. For this website, I will call this box `gateway`.\n\nI'ved named all three physical compute nodes after cats:\n\n 1. [`aslan`](https://en.wikipedia.org/wiki/Aslan) - AMD Threadripper system, and main computer node\n 2. [`green-lion`](https://en.wikipedia.org/wiki/Suns_in_alchemy) - Large Protectli vault\n 3. [`bagheera`](https://en.wikipedia.org/wiki/Bagheera) - Old MSI latop\n\n Click on the links to see a bit behind each name. I must confess, I'm not fully aware of the history of `green-lion` within the field of alchemy, so I hope it doesn't mean something terrible!\n\nAccording to ChatGPT:\n\n>In essence, the Green Lion is a metaphor for transformation, representing both the destructive and creative forces in alchemy.\n\n\n These are running in containers manually deployed using [Docker Compose](https://docs.docker.com/compose/). Most of them are running on `aslan`, with some running in \"high availability\" mode, with containers running on both `aslan` and `green-lion`. An [nginx](nginx.com) reverse proxy runs on `gateway` proxying traffic and terminating SSL using [Let's Encrypt](letsencrypt.org).\n\n I'd like to leave all of these services running with close to zero downtime, while deploying new services using increasingly more advanced techniques, culminating in a platform built on top of Kubernetes.\n\n To do so, I'm going to first get some automation in place to configure and manage these physical servers. Then I'll move the manual configuration of my existing service into Ansible, and then from there will setup CI using [Drone CI](drone.io).\n\n# Installing and testing Ansible\n\n## What is Ansible. Why am I using it?\n\nI've used Ansible a few times to deploy web applications and configure servers. I don't love the giant collection of templated YAML, and yet, it provides too much value to ignore.\n\nAs described on their homepage:\n\n> Ansible is an open source IT automation engine that automates provisioning, configuration management, application deployment, orchestration, and many other IT processes. It is free to use, and the project benefits from the experience and intelligence of its thousands of contributors.\n\nIn my words, Ansible is a tool that let's you write YAML file that describe actions that should be taken on a collection of servers, including copying files, installing software and more. When structured and written well, Ansible \"Playbooks\" are [[idempotent]], and repeatable.\n\nI'm going to be using ansible primarily to manage the physical servers before any additional infrastructure is in place.\n\n\n## Requirements\n\nBefore we can use ansible, we need passwordless sudo ssh access to all nodes.\n\nRepeat this step for all physical nodes that you wish to manage with Ansible. I'm going to target `aslan` and `green-lion` initially, and then maybe move onto `gateway` and `bagheera` later.\n\n### 1. Passwordless sudo ansible_user account\n\n\n1. Create a new user named `ansible_user`:\n\n```\nsudo adduser ansible_user\n```\n\n2. Give `ansible_user` sudo access without requiring a password:\n\n```\necho \"ansible_user ALL=(ALL) NOPASSWD:ALL\" | sudo tee /etc/sudoers.d/ansible_user\n```\n\n3. Set up SSH key authentication for `ansible_user`:\n\n```\nsudo mkdir -p /home/ansible_user/.ssh\nsudo chmod 700 /home/ansible_user/.ssh\nsudo touch /home/ansible_user/.ssh/authorized_keys\nsudo chmod 600 /home/ansible_user/.ssh/authorized_keys\n```\n\n4. Copy your public SSH key into the `authorized_keys` file:\n\n```\nsudo sh -c 'echo \"YOUR_PUBLIC_SSH_KEY\" >> /home/ansible_user/.ssh/authorized_keys'\n```\n\n   Replace `YOUR_PUBLIC_SSH_KEY` with your actual public SSH key.\n\n5. Set proper ownership for the `.ssh` directory and its contents:\n\n```\nsudo chown -R ansible_user:ansible_user /home/ansible_user/.ssh\n```\n\nAfter completing these steps, you should be able to SSH into the server as `ansible_user` using your SSH key, and execute sudo commands without a password prompt.\n\n### 2: Ansible installed on local development machine\n\nTo install Ansible on your local development machine, follow these steps:\n\n1. Create a virtual environment:\n\n```bash\npython3 -m venv ansible-venv\n```\n\n2. Activate the virtual environment:\n\n```bash\nsource ansible-venv/bin/activate\n```\n\n3. Install Ansible within the virtual environment:\n\n```bash\npip install ansible\n```\n\n4. Verify the installation:\n\n```bash\nansible --version\n```\n\nThis approach isolates Ansible and its dependencies in a dedicated environment, preventing conflicts with other Python packages on your system.\n\n## Create Ansible inventory and test connectivity\n\nCreate the following files and directory structure\n\n``` bash\n$ tree physical-server-ansible-playbook\n\u251c\u2500\u2500 ansible.cfg\n\u251c\u2500\u2500 inventory\n\u2502   \u2514\u2500\u2500 hosts\n\u251c\u2500\u2500 playbook.yml\n\u2514\u2500\u2500 roles\n    \u2514\u2500\u2500 hello\n        \u2514\u2500\u2500 tasks\n            \u2514\u2500\u2500 main.yml\n```\n\n```bash\ncat ansible.cfg\n[defaults]\ninventory = inventory/hosts\nremote_user = ansible_user\nprivate_key_file = ~/.ssh/id_ed25519_aslan_ansible\nhost_key_checking = False\ninterpreter_python = auto_silent\n```\n\n```bash\n[lz]\ncat inventory/hosts\naslan ansible_host=aslan\ngreen-lion ansible_host=green-lion\n\n[all:vars]\nansible_user=ansible_user\nansible_ssh_private_key_file=~/.ssh/id_ed25519_aslan_ansible\n```\n\n\nOf note, make sure the ssh key is correct in `ansible.cfg`. Also note that `host_key_checking = False` is a potential security risk. I'm running this on my home LAN so I think I'm good, but just be aware.\n\nI've called this group of servers the \"lz\" for landing zone. I'll continue the metaphor, as I \"land\" on a distant planet and begin \"terraforming.\"\n\n\nTo verify this is working you can run the ansible ping command\n\n```bash\nansible all -m ping                                                                                                                                                                                                                 \u2718 1 master \u2b06 \u2731 \u25fc\ngreen-lion | UNREACHABLE! => {\n    \"changed\": false,\n    \"msg\": \"Failed to connect to the host via ssh: ansible_user@10.0.0.22: Permission denied (publickey).\",\n    \"unreachable\": true\n}\naslan | SUCCESS => {\n    \"ansible_facts\": {\n        \"discovered_interpreter_python\": \"/usr/bin/python3.11\"\n    },\n    \"changed\": false,\n    \"ping\": \"pong\"\n}\n```\n\nAs you can see, my connectivity to `green-lion` is not correct. I'll go ahead and make the ansible user on `green-lion` and try again.\n\n\n```bash\nansible all -m ping                                                                                                                                                                                                                     master \u2b06 \u2731 \u25fc\naslan | SUCCESS => {\n    \"ansible_facts\": {\n        \"discovered_interpreter_python\": \"/usr/bin/python3.11\"\n    },\n    \"changed\": false,\n    \"ping\": \"pong\"\n}\ngreen-lion | SUCCESS => {\n    \"ansible_facts\": {\n        \"discovered_interpreter_python\": \"/usr/bin/python3.10\"\n    },\n    \"changed\": false,\n    \"ping\": \"pong\"\n}\n```\n\n\n## Next Steps\n\nAs you may be able to guess simply from the direction of this blog, I like automating things. In my next post I'll describe how a securely store secrets for usage within Ansible playbooks, and how I create initial random secrets usable for passwords and keys for deployed software.\n\nRead more in [[blog/02-ansible-secrets]].\n\n\n## Untested Sketchy Scripts\n\nI made a script for setting up the Ansible user on a remote machine. This assumes that you have SSH access to an account with sudo permissions on the remote server.\n\nThis may break for various reasons, but it has worked for me.\n\n```Python\n#!/usr/bin/env python3\nimport os\nimport subprocess\nimport sys\nimport getpass\n\ndef run_ssh_command(hostname, command, control_path=None, use_sudo=False):\n    ssh_command = ['ssh']\n    if control_path:\n        ssh_command.extend(['-S', control_path])\n    \n    if use_sudo:\n        full_command = f\"sudo -S bash -c '{command}'\"\n    else:\n        full_command = command\n\n    ssh_command.extend([hostname, full_command])\n    \n    if use_sudo:\n        sudo_password = getpass.getpass(f\"Enter sudo password for {hostname}: \")\n        process = subprocess.Popen(ssh_command, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n        stdout, stderr = process.communicate(input=sudo_password + '\\n')\n    else:\n        result = subprocess.run(ssh_command, capture_output=True, text=True)\n        stdout, stderr = result.stdout, result.stderr\n\n        if result.returncode != 0:\n            print(f\"Error running command: {command}\")\n            print(\"Remote host stderr output:\")\n            print(stderr.strip())\n            raise subprocess.CalledProcessError(result.returncode, ssh_command)\n    return stdout.strip()\n\ndef get_ssh_keys():\n    ssh_dir = os.path.expanduser(\"~/.ssh\")\n    return [f for f in os.listdir(ssh_dir) if f.endswith(\".pub\")]\n\ndef prompt_for_ssh_key(keys):\n    print(\"Available SSH public keys:\")\n    for i, key in enumerate(keys):\n        print(f\"{i + 1}: {key}\")\n    choice = int(input(\"Select the number of the SSH key to use: \")) - 1\n    return keys[choice]\n\ndef check_user_exists(hostname, control_path):\n    return run_ssh_command(hostname, 'id -u ansible_user', control_path).isdigit()\n\ndef check_sudo_permissions(hostname, control_path):\n    return \"NOPASSWD: ALL\" in run_ssh_command(hostname, 'sudo -l -U ansible_user', control_path, use_sudo=True)\n\ndef enable_ansible_user(hostname, ssh_key, control_path):\n    if check_user_exists(hostname, control_path):\n        if check_sudo_permissions(hostname, control_path):\n            print(f\"User ansible_user already exists with appropriate sudo permissions.\")\n            return\n        else:\n            print(f\"User ansible_user exists but does not have appropriate sudo permissions.\")\n            return\n\n    commands = [\n        'adduser --disabled-password --gecos \"\" ansible_user',\n        'echo \"ansible_user ALL=(ALL) NOPASSWD:ALL\" | tee /etc/sudoers.d/ansible_user',\n        'mkdir -p /home/ansible_user/.ssh',\n        'chmod 700 /home/ansible_user/.ssh',\n        'touch /home/ansible_user/.ssh/authorized_keys',\n        'chmod 600 /home/ansible_user/.ssh/authorized_keys',\n        f'echo \"{ssh_key}\" | tee -a /home/ansible_user/.ssh/authorized_keys',\n        'chown -R ansible_user:ansible_user /home/ansible_user/.ssh'\n    ]\n    for command in commands:\n        run_ssh_command(hostname, command, control_path, use_sudo=True)\n\nif __name__ == \"__main__\":\n    if len(sys.argv) != 2:\n        print(\"Usage: enable_ansible <hostname>\")\n        sys.exit(1)\n\n    hostname = sys.argv[1]\n    keys = get_ssh_keys()\n    if not keys:\n        print(\"No SSH public keys found in ~/.ssh\")\n        sys.exit(1)\n\n    selected_key = prompt_for_ssh_key(keys)\n    ssh_key_path = os.path.expanduser(f\"~/.ssh/{selected_key}\")\n    with open(ssh_key_path, 'r') as key_file:\n        ssh_key = key_file.read().strip()\n\n    control_path = f\"/tmp/ansible-ssh-{hostname}-22-control\"\n    \n    # Set up the control master connection\n    subprocess.run(['ssh', '-M', '-S', control_path, '-fNT', hostname], check=True)\n    \n    try:\n        enable_ansible_user(hostname, ssh_key, control_path)\n        print(f\"Ansible user enabled on {hostname} with SSH key {selected_key}\")\n    finally:\n        # Close the control master connection\n        subprocess.run(['ssh', '-S', control_path, '-O', 'exit', hostname], check=True)\n```"
    },
    "/blog": {
        "title": "index",
        "date": "2024-09-22",
        "tags": [],
        "publish": true,
        "url": "/blog",
        "path": "blog/index.md",
        "content": "# Blog\n\n## Subtitle\n\n### Foo\n\n\n```Python\n\ndef foo():\n    print(\"Hello, world!\")\n```"
    },
    "/blog/2024-09-16-personal-infrastructure-part-4:-creating-and-storing-initial-secrets": {
        "title": "Personal Infrastructure Part 4: Creating and Storing Initial Secrets",
        "date": "2024-09-16",
        "tags": [
            "blog",
            "development",
            "infrastructure",
            "ansible"
        ],
        "publish": true,
        "url": "/blog/2024-09-16-personal-infrastructure-part-4:-creating-and-storing-initial-secrets",
        "path": "blog/04-initial-secrets.md",
        "content": "![Image of secrets being created in space](/images/ansible-vault-secrets-1.webp)\n\n\nIn this post, I describe my technique for automating the creation of initial secrets for usage in Ansible playbooks.\n\nMost applications need some secret state for operation. This include passwords for database connections, random numbers used for security purposes, API keys, SSH keys and more.\n\nSome of these secrets are user-defined, and some come from third party or external services. User-defined secrets need to generated at least once when deploying the application, and possibly more if a secret rotation strategy is used. For this post, I will describe a simple way to generate secrets that integrates nicely with Ansible.\n\nSome people prefer to use features built into Ansible, such as [`ansible.builtin.password`](https://docs.ansible.com/ansible/latest/collections/ansible/builtin/password_lookup.html), but I'd rather use my method as it integrates nicely into my vault setup and gracefully handles adding new initial secrets throughout the development process. \n\n## Technique\n\nI use a small python program to manage creation of secrets. I use this in combination with the Ansible Vault and a an ansible `role` to create secrets on first run and if new secrets are created and store them in a vault, and then inject them as `facts` into the subsequent roles\n\n**Python Program**\nThe python program takes in a list of secrets from stdin, the name of a YAML file, and outputs a YAML file that has a secret for each one specified via command line. The program will also preserve any secrets that are not specified, allowing manually added secrets to be stored in the same vault. \n\n\n```Python\nimport argparse\nimport random\nimport string\nimport yaml\nimport sys\n\ndef generate_secret(length=64):\n    \"\"\"Generate a random alphanumeric secret of specified length.\"\"\"\n    characters = string.ascii_letters + string.digits\n    return ''.join(random.choice(characters) for _ in range(length))\n\ndef create_secrets_yaml(identifiers, existing_secrets=None):\n    \"\"\"Create a dictionary of secrets for given identifiers.\"\"\"\n    secrets = {}\n    for identifier in identifiers:\n        if existing_secrets and identifier in existing_secrets:\n            secrets[identifier] = existing_secrets[identifier]\n        else:\n            secrets[identifier] = generate_secret()\n    return yaml.dump(secrets, default_flow_style=False)\n\ndef regenerate_secrets(secrets, identifiers_to_regenerate):\n    \"\"\"Regenerate secrets for specified identifiers.\"\"\"\n    for identifier in identifiers_to_regenerate:\n        if identifier in secrets:\n            secrets[identifier] = generate_secret()\n    return secrets\n\ndef get_changed_names(old_secrets, new_secrets):\n    \"\"\"Get the list of added, removed, and changed secret names.\"\"\"\n    added = set(new_secrets.keys()) - set(old_secrets.keys())\n    removed = set(old_secrets.keys()) - set(new_secrets.keys())\n    changed = {k for k in old_secrets.keys() & new_secrets.keys() if old_secrets[k] != new_secrets[k]}\n    return added, removed, changed\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Generate, edit, add, or remove secrets for given identifiers.\")\n    parser.add_argument('identifiers', nargs='*', help='List of identifiers to generate secrets for')\n    parser.add_argument('--regenerate', nargs='*', help='List of identifiers to regenerate secrets for')\n    parser.add_argument('--changed-names', action='store_true', help='Output what keys were added, removed or changed')\n    args = parser.parse_args()\n\n    # Read existing secrets from stdin if provided\n    existing_secrets = {}\n    if not sys.stdin.isatty():\n        existing_secrets = yaml.safe_load(sys.stdin)\n\n    old_secrets = existing_secrets.copy()\n\n    # Regenerate specified secrets\n    if args.regenerate:\n        existing_secrets = regenerate_secrets(existing_secrets, args.regenerate)\n\n    # Generate new secrets\n    new_secrets = yaml.safe_load(create_secrets_yaml(args.identifiers, existing_secrets))\n\n    # Output changed names if requested\n    if args.changed_names:\n        added, removed, changed = get_changed_names(old_secrets, new_secrets)\n        for name in added:\n            print(f\"+ {name}\")\n        for name in removed:\n            print(f\"- {name}\")\n        for name in changed:\n            print(f\"~ {name}\")\n    else:\n        # Output the YAML\n        print(yaml.dump(new_secrets, default_flow_style=False))\n\n```\n\n\nI created the following Ansible `role` to generate the initial secrets:\n\n```YAML\n---\n- name: Check if secrets file already exists\n  stat:\n    path: \"{{ playbook_dir }}/secrets/secrets.yml\"\n  register: secrets_file\n\n- name: Ensure secrets directory exists\n  file:\n    path: \"{{ playbook_dir }}/secrets\"\n    state: directory\n    mode: '0700'\n\n- name: Generate or update secrets\n  block:\n    - name: View existing secrets\n      ansible.builtin.shell: ansible-vault view {{ playbook_dir }}/secrets/secrets.yml\n      register: existing_secrets\n      when: secrets_file.stat.exists\n\n    - name: Check for changes in secrets\n      ansible.builtin.shell: >\n        {% if secrets_file.stat.exists %}\n        echo \"{{ existing_secrets.stdout }}\" | \n        {% endif %}\n        python3 {{ role_path }}/files/manage_secrets.py {{ initial_secrets | join(' ') }} --changed-names\n      register: secrets_changes\n\n    - name: Generate or update secrets using manage_secrets.py\n      ansible.builtin.shell: >\n        {% if secrets_file.stat.exists %}\n        echo \"{{ existing_secrets.stdout }}\" | \n        {% endif %}\n        python3 {{ role_path }}/files/manage_secrets.py {{ initial_secrets | join(' ') }}\n      register: secrets_output\n      when: secrets_changes.stdout != \"\"\n\n    - name: Create temporary secrets file\n      copy:\n        content: \"{{ secrets_output.stdout }}\"\n        dest: \"{{ playbook_dir }}/secrets/temp_secrets.yml\"\n        mode: '0600'\n      when: secrets_changes.stdout != \"\"\n\n    - name: Encrypt secrets file with Ansible Vault\n      command: >\n        ansible-vault encrypt \n        {{ playbook_dir }}/secrets/temp_secrets.yml\n      register: encrypt_result\n      when: secrets_changes.stdout != \"\"\n\n    - name: Rename encrypted secrets file\n      command: mv {{ playbook_dir }}/secrets/temp_secrets.yml {{ playbook_dir }}/secrets/secrets.yml\n      when: secrets_changes.stdout != \"\" and encrypt_result.rc == 0\n\n    - name: Clean up temporary files\n      file:\n        path: \"{{ playbook_dir }}/secrets/temp_secrets.yml\"\n        state: absent\n      when: secrets_changes.stdout != \"\" and encrypt_result.rc != 0\n\n    - name: Display success message\n      debug:\n        msg: \"Secrets file {% if secrets_file.stat.exists %}updated{% else %}created{% endif %} and encrypted successfully at {{ playbook_dir }}/secrets/secrets.yml\"\n      when: secrets_changes.stdout != \"\"\n\n    - name: Display no changes message\n      debug:\n        msg: \"No changes detected in secrets file. Skipping re-encryption.\"\n      when: secrets_changes.stdout == \"\"\n```\n\n\nWith these two components in place, all that is left to do is load the secrets into [`facts`](https://www.redhat.com/sysadmin/playing-ansible-facts), and use them in other roles in my playbook.\n\n```YAML\n- name: Web Servers\n  hosts: web:!localhost\n  tags: [remote, staging]\n  tasks:\n    - name: Include the encrypted secrets file as variables\n      ansible.builtin.include_vars:\n        file: \"inventories/{{ env }}/group_vars/secrets.yaml\"\n      tags: [always]\n\n    - name: Setup Web servers\n      ansible.builtin.include_role:\n        name: deploy_site\n```"
    },
    "/blog/2024-09-02-personal-microservices-infrastructure-project": {
        "title": "Personal Microservices Infrastructure Project",
        "date": "2024-09-02",
        "tags": [
            "devops",
            "programming",
            "kubernetes",
            "hashicorp",
            "terraform",
            "homelab"
        ],
        "publish": true,
        "url": "/blog/2024-09-02-personal-microservices-infrastructure-project",
        "path": "blog/01-personal-infrastructure.md",
        "content": "![Image of people building their own digital infrastructure](/images/personal-cloud.png)\n\nJoin me as I build a personal datacenter, a \u201chomelab\u201d suitable for playing with microservices infrastructure. This is the first chapter of a story where people reclaim their power from their digital lords, and grow into equal peers in the digital realm.\n\nI am starting my portion of this journey by arranging computer and software components to build a datacenter to serve as the foundation of a \"Personal Cloud.\" This personal cloud will create my own digital sovereign territory from which I can steward my information and define my interaction with my peers. This personal cloud is intended as a proof of concept of what a better internet could look like.\n\n### Introduction\n\nThere was a time when only a few wealthy people had books. There was a time when only a few people had telephones. There was a time when only a few people had computers. We are now in an era where many people have easy access to these modern information technologies. In this era, there are only a few people who have their own datacenter. Everything is in \u201cthe cloud\u201d, a new form of digital feudalism reigns supreme. Most people life as serfs, graciously accepting the few crumbs of value that trickle down in the form of apps and services while those people controlling them accumulate wealth and power.\n\n## The Nitty Gritty\n\nThis project aims to create a comprehensive, real-world microservices architecture, focusing on automation, scalability, and best practices in modern DevOps.\n\nI'll write developer journal entries as blog posts, as well as organize them into a more structured \"how-to\" documentation suitable for recreating the project or following along. I\u2019ll also write the occasional essay about the meaning and \u2018philosophy\u2019 motivating my actions.\u00a0\n\nAs of now, I've done some preliminary research and have come up with this plan of action. As I go ahead and my hands dirty, I imagine some of this plan will change, either slightly or dramatically as I learn from my mistakes and refine my understanding.\n\n### Tentative Plan of Action\n\n#### 1. Physical Server Setup\n  - [[blog/01-ansible-setup]]\n  - [[blog/02-ansible-secrets]]\n  - [[blog/03-simple-automation]]\n  - [[blog/04-initial-secrets]]\n\n#### 2. CI Runner Setup:\n   - Install and configure a CI tool (likely [Drone CI](https://www.drone.io/))\n   - Migrate legacy services to Ansible, deployed by CI\n   - Automatically run Ansible on infrastructure code changes.\n\n#### 3. Core Services\nIn this phase, I will deploy a small cluster of virtual machines that will host \u201ccore services\u201d that will make deploying production services easier and more repeatable.\n\n- Use [Packer](https://www.packer.io/) for creating standardized VM images\n- Implement [Terraform](https://www.terraform.io/) for infrastructure provisioning\n- Setup [Headscale](https://www.headscale.net/) for secure networking\n- Set up [Nomad](https://www.nomadproject.io/) for initial workload orchestration\n- Deploy [Vault](https://www.vaultproject.io/) for secrets management\n- Set up monitoring tools (e.g., [Prometheus](https://prometheus.io/), [Grafana](https://grafana.com/))\n- Implement logging solution (e.g., [ELK Stack](https://www.elastic.co/elastic-stack))\n\n#### 4. Advanced Orchestration:\n   - Create a separate Nomad cluster for application workloads\n   - Potentially set up [K3s](https://k3s.io/) (lightweight Kubernetes) within Nomad\n\n#### 5. Network and Security:\n   - Implement ingress controllers and load balancers\n   - Set up network policies and firewalls\n\n#### 6. Automation and Scalability:\n   - Develop scripts and workflows for rapid cluster creation\n   - Implement auto-scaling and self-healing capabilities\n#### 7. Begin deploying Services\n\nIn this phase, I will begin with the working foundation to deploy modern applications that I\u2019ve build in subsequent steps. From here I will begin to make this cloud more personal, and develop applications and services on top of it that are valuable to me, and demonstrate the value of a personal cloud.\n\n### Learning Objectives\n\nWhy am I doing this? I'd like to learn these tools, and build something useful for myself and others. I have a large project in mind, and I will discuss it after I build the initial proof of concept \"personal cloud\".\n\nPut into dry bullet points, I'd like to:\n\n- Gain hands-on experience with modern DevOps tools and practices\n- Understand whether microservices architecture is a good fit for my project\n- Develop skills in automation, security, and scalability in distributed systems\n- Build something useful for myself and others\n\n### Sharing Knowledge\n\nThroughout this project, I will:\n\n  - Document each step in this developer journal or blog\n  - Create some guides and tutorials\n  - Share challenges faced and solutions implemented. I'd like to specifically share my perspective, from someone new to \n    modern DevOps, though no stranger to software engineering.\n  - Possibly create video content"
    }
}